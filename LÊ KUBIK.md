# ğŸ“– LÃª Kubik - Guia do Consumidor Kafka

**Para**: Kubik  
**De**: Francisco  
**Assunto**: Setup do Produtor Kafka e Como Consumir os Dados

---

## ğŸ¯ Resumo Executivo

Criei um sistema Kafka que recebe dados de sensores de proximidade do telemÃ³vel (via app ZIG SIM) e publica-os num tÃ³pico Kafka chamado **`sensor.raw`**.

**O que precisas fazer**: Consumir mensagens do tÃ³pico `sensor.raw` a partir do broker Kafka que estÃ¡ no meu PC.

---

## ğŸ—ï¸ Arquitetura do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ZIG SIM App   â”‚ (TelemÃ³vel)
â”‚   (Sensor)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ UDP porta 5000
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UDP â†’ HTTP     â”‚ (Python script no PC1)
â”‚    Adapter      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP POST localhost:8000
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ sensor-gateway  â”‚ (FastAPI em Docker)
â”‚  MicroserviÃ§o   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Kafka Protocol
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kafka Broker   â”‚ (Docker)  â† AQUI CONSOMES!
â”‚  pc-kafka:9092  â”‚
â”‚  TÃ³pico:        â”‚
â”‚  sensor.raw     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ InformaÃ§Ã£o TÃ©cnica do Kafka

### ConfiguraÃ§Ã£o do Broker

| ParÃ¢metro | Valor | Notas |
|-----------|-------|-------|
| **Hostname** | `pc-kafka` | Nome lÃ³gico do broker |
| **IP** | `<IP do PC1>` | A descobrir na rede local |
| **Porta** | `9092` | Porta padrÃ£o Kafka |
| **Bootstrap Servers** | `pc-kafka:9092` | String de conexÃ£o |
| **VersÃ£o Kafka** | 7.6.0 (Confluent) | Imagem Docker |

### InformaÃ§Ã£o do TÃ³pico

| ParÃ¢metro | Valor |
|-----------|-------|
| **Nome do TÃ³pico** | `sensor.raw` |
| **PartiÃ§Ãµes** | 1 (default) |
| **Replication Factor** | 1 |
| **Formato** | JSON (UTF-8) |
| **Retention** | Default (7 dias) |

---

## ğŸ“¨ Formato das Mensagens

### Schema do JSON

Cada mensagem no tÃ³pico `sensor.raw` tem este formato:

```json
{
  "id": 1,
  "ocupado": true,
  "timestamp": "2025-12-11T20:10:15.123Z"
}
```

### Campos

| Campo | Tipo | DescriÃ§Ã£o | Valores PossÃ­veis |
|-------|------|-----------|-------------------|
| `id` | `int` | Identificador do sensor (fixo) | `1` |
| `ocupado` | `boolean` | Estado de ocupaÃ§Ã£o do sensor | `true` / `false` |
| `timestamp` | `string` | Timestamp ISO 8601 com milissegundos | `YYYY-MM-DDTHH:mm:ss.fffZ` |

### Exemplos de Mensagens

**Sensor detetou ocupaÃ§Ã£o:**
```json
{
  "id": 1,
  "ocupado": true,
  "timestamp": "2025-12-11T20:10:15.456Z"
}
```

**Sensor detetou desocupaÃ§Ã£o:**
```json
{
  "id": 1,
  "ocupado": false,
  "timestamp": "2025-12-11T20:10:20.789Z"
}
```

---

## ğŸ”Œ Como Conectar ao Kafka (Para Kubik)

### Passo 1: Configurar o ficheiro `hosts`

Para te ligares ao Kafka usando o hostname `pc-kafka`, adiciona ao teu ficheiro hosts:

**Windows** (`C:\Windows\System32\drivers\etc\hosts`):
```
<IP_DO_PC1>   pc-kafka
```

**Linux/Mac** (`/etc/hosts`):
```
<IP_DO_PC1>   pc-kafka
```

> âš ï¸ **Importante**: Substitui `<IP_DO_PC1>` pelo IP real do meu PC na rede local.  
> Para descobrir, eu executo `ipconfig` no Windows ou `ip addr` no Linux.

### Passo 2: Testar Conectividade

Antes de configurar o teu consumer, testa se consegues alcanÃ§ar o broker:

**OpÃ§Ã£o A - Ping:**
```bash
ping pc-kafka
```

**OpÃ§Ã£o B - Telnet (verificar porta 9092):**
```bash
telnet pc-kafka 9092
```

**OpÃ§Ã£o C - Kafka Console Consumer (se tiveres Kafka instalado):**
```bash
kafka-console-consumer \
  --bootstrap-server pc-kafka:9092 \
  --topic sensor.raw \
  --from-beginning
```

---

## ğŸ’» CÃ³digo de Exemplo para Consumir

### Python (kafka-python)

```python
from kafka import KafkaConsumer
import json

# Configurar consumer
consumer = KafkaConsumer(
    'sensor.raw',
    bootstrap_servers=['pc-kafka:9092'],
    auto_offset_reset='earliest',  # Ler desde o inÃ­cio
    enable_auto_commit=True,
    group_id='kubik-consumer-group',  # Teu grupo de consumidores
    value_deserializer=lambda x: json.loads(x.decode('utf-8'))
)

print("ğŸ§ A ouvir mensagens do tÃ³pico sensor.raw...")

# Consumir mensagens
for message in consumer:
    data = message.value
    print(f"ğŸ“¨ Recebido: ID={data['id']}, Ocupado={data['ocupado']}, Timestamp={data['timestamp']}")
    
    # Processar a mensagem
    if data['ocupado']:
        print("âœ… Sensor OCUPADO")
    else:
        print("âŒ Sensor LIVRE")
```

**Instalar dependÃªncias:**
```bash
pip install kafka-python
```

---

### Java (Spring Kafka)

**application.yml:**
```yaml
spring:
  kafka:
    bootstrap-servers: pc-kafka:9092
    consumer:
      group-id: kubik-consumer-group
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
```

**Consumer Class:**
```java
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;
import com.fasterxml.jackson.databind.ObjectMapper;

@Service
public class SensorConsumer {
    
    private final ObjectMapper objectMapper = new ObjectMapper();
    
    @KafkaListener(topics = "sensor.raw", groupId = "kubik-consumer-group")
    public void consume(String message) {
        try {
            SensorData data = objectMapper.readValue(message, SensorData.class);
            System.out.println("ğŸ“¨ Recebido: " + data);
            
            if (data.isOcupado()) {
                System.out.println("âœ… Sensor OCUPADO");
            } else {
                System.out.println("âŒ Sensor LIVRE");
            }
        } catch (Exception e) {
            System.err.println("Erro ao processar mensagem: " + e.getMessage());
        }
    }
}

// DTO
class SensorData {
    private int id;
    private boolean ocupado;
    private String timestamp;
    
    // Getters e Setters
}
```

---

### Node.js (KafkaJS)

```javascript
const { Kafka } = require('kafkajs');

// Configurar Kafka client
const kafka = new Kafka({
  clientId: 'kubik-consumer',
  brokers: ['pc-kafka:9092']
});

const consumer = kafka.consumer({ 
  groupId: 'kubik-consumer-group' 
});

const run = async () => {
  await consumer.connect();
  await consumer.subscribe({ 
    topic: 'sensor.raw', 
    fromBeginning: true 
  });

  await consumer.run({
    eachMessage: async ({ topic, partition, message }) => {
      const data = JSON.parse(message.value.toString());
      console.log(`ğŸ“¨ Recebido:`, data);
      
      if (data.ocupado) {
        console.log('âœ… Sensor OCUPADO');
      } else {
        console.log('âŒ Sensor LIVRE');
      }
    },
  });
};

run().catch(console.error);
```

**Instalar dependÃªncias:**
```bash
npm install kafkajs
```

---

## ğŸ› ï¸ Ferramentas Ãšteis

### Kafka UI (Recomendado para Debug)

Podes aceder Ã  interface web do Kafka UI para verificar mensagens antes de implementar o consumer:

```
http://pc-kafka:8080
```

**Funcionalidades:**
- âœ… Ver mensagens do tÃ³pico `sensor.raw` em tempo real
- âœ… Pesquisar e filtrar mensagens
- âœ… Ver estatÃ­sticas de consumo
- âœ… Monitorizar lag dos consumidores

---

## ğŸ” InformaÃ§Ã£o Adicional

### Como Funciona o Produtor (Para Contexto)

1. **ZIG SIM** (app de telemÃ³vel) envia dados do sensor de proximidade via **UDP** para o meu PC
2. **UDP Adapter** (script Python) recebe UDP e converte para HTTP POST
3. **Sensor Gateway** (microserviÃ§o FastAPI) recebe o JSON "grande" do ZIG SIM
4. **TransformaÃ§Ã£o**: Extrai apenas `proximitymonitor` e `timestamp`, cria JSON simples
5. **PublicaÃ§Ã£o**: Envia para Kafka no tÃ³pico `sensor.raw`

### Dados Originais do ZIG SIM (Antes da TransformaÃ§Ã£o)

Para contexto, o JSON original que o ZIG SIM envia Ã© este:

```json
{
  "device": {
    "name": "unknown device (iPhone14,3)",
    "displayheight": 2208,
    "uuid": "U8sb1vgccfEWIlZC",
    "os": "ios",
    "osversion": "18.5",
    "displaywidth": 1242
  },
  "timestamp": "2025_12_11_19:22:06.190",
  "sensordata": {
    "proximitymonitor": {
      "proximitymonitor": true
    }
  }
}
```

O meu **sensor-gateway** simplifica isto para:

```json
{
  "id": 1,
  "ocupado": true,
  "timestamp": "2025-12-11T19:22:06.190Z"
}
```

---

## âœ… Checklist para Kubik

Antes de comeÃ§ar a consumir, verifica:

- [ ] Adicionei `pc-kafka` ao ficheiro hosts
- [ ] Consigo fazer ping para `pc-kafka`
- [ ] (Opcional) Acedi ao Kafka UI em `http://pc-kafka:8080` e vi mensagens no tÃ³pico `sensor.raw`
- [ ] Escolhi uma biblioteca Kafka (kafka-python, Spring Kafka, KafkaJS, etc.)
- [ ] Configurei o `bootstrap-server` como `pc-kafka:9092`
- [ ] Configurei o `topic` como `sensor.raw`
- [ ] Defini um `group-id` Ãºnico (ex: `kubik-consumer-group`)
- [ ] Implementei deserializaÃ§Ã£o JSON das mensagens
- [ ] Testei receber mensagens

---

## ğŸ†˜ Troubleshooting

### Problema: "Connection refused" ou "Unable to connect to Kafka"

**Causas possÃ­veis:**
1. Hostname `pc-kafka` nÃ£o configurado no `/etc/hosts`
2. Firewall no PC1 estÃ¡ a bloquear a porta 9092
3. O Docker nÃ£o estÃ¡ a correr no PC1

**SoluÃ§Ã£o:**
- Verificar ficheiro hosts
- Pedir-me para abrir porta 9092 no firewall do Windows
- Confirmar comigo se o Kafka estÃ¡ up: `docker ps` deve mostrar container `kafka`

### Problema: "Topic does not exist"

**SoluÃ§Ã£o:**
O tÃ³pico `sensor.raw` Ã© criado automaticamente quando a primeira mensagem Ã© enviada. Se ainda nÃ£o existir:
- Envia uma mensagem de teste do ZIG SIM
- Ou cria manualmente o tÃ³pico (posso fazer isso se precisares)

### Problema: Consumer nÃ£o recebe mensagens

**Checklist:**
1. Confirma que `auto.offset.reset` estÃ¡ configurado (usa `earliest` para ler desde o inÃ­cio)
2. Verifica se hÃ¡ mensagens no tÃ³pico via Kafka UI
3. Confirma que o `group-id` estÃ¡ correto
4. VÃª se hÃ¡ erros de deserializaÃ§Ã£o JSON

---

## ğŸ“ Contacto

Se tiveres problemas ou dÃºvidas:

1. Verifica primeiro o **Kafka UI** (`http://pc-kafka:8080`) para confirmar que as mensagens estÃ£o a chegar
2. Envia-me os logs de erro do teu consumer
3. Posso partilhar-te logs do meu produtor (`sensor-gateway`)

**Ferramentas de debug que podes usar:**
- Kafka Console Consumer (CLI)
- Kafka UI (Web)
- Logs do teu consumer

---

**VersÃ£o**: 1.0  
**Data**: 2025-12-11  
**Status**: âœ… Sistema em produÃ§Ã£o e funcional

Boa sorte com a implementaÃ§Ã£o! ğŸš€
